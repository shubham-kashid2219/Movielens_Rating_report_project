{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b621bb9b-c949-450e-92c9-8a544e6d0b80",
   "metadata": {},
   "source": [
    "# === MovieLens Data Pipeline Project ==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6297b90b-324d-42d8-9cbc-bd7f3663934e",
   "metadata": {},
   "source": [
    "#### == Importing time module for printing execution time of the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2384903a-b33f-4106-8ca1-779860b2f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf11767-6f9e-4363-99e2-44dc8aefdd10",
   "metadata": {},
   "source": [
    "#### == Importing findspark module to integrate pyspark with jupyter notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e56ad03-9788-4f46-8e02-08dc93070bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dbcbf9-20e6-4c1a-94ed-820f77cf9355",
   "metadata": {},
   "source": [
    "#### == Create SparkSession for spark application \"MovieLens Data Pipeline Project\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90605048-b919-4349-bd30-cba28c8e9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local').appName(\"MovieLens Data Pipeline Project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d443f6e-0242-40ee-a381-549aa1c8dadc",
   "metadata": {},
   "source": [
    "#### == Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf435539-0091-4697-a175-8a211c18da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, FloatType\n",
    "\n",
    "from pyspark.sql.functions import regexp_extract, explode, split, trim, broadcast, avg, count, col, desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf002ec1-ccab-4fa1-b368-d7c70405005a",
   "metadata": {},
   "source": [
    "#### == Reading \"movies.dat\" in pyspark dataframe \"movies_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cae610e6-3275-4762-b216-5215c777beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom schema for \"movies_df\"\n",
    "movies_schema = StructType([\n",
    "    StructField(\"MovieID\", IntegerType(), True),\n",
    "    StructField(\"Title\", StringType(), True),\n",
    "    StructField(\"Genres\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create \"movies_df\" dataframe by reading data from file \"movies.dat\"\n",
    "movies_df = spark.read.format('csv') \\\n",
    "                    .option(\"sep\", \"::\") \\\n",
    "                    .schema(movies_schema) \\\n",
    "                    .option(\"mode\", \"permissive\") \\\n",
    "                    .load(r\"..\\..\\staging\\dimension\\movies.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a750d2da-9c15-4390-b961-d42511c14a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3883"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract \"Release\"\n",
    "year_pattern = r\"\\((\\d{4})\\)\"\n",
    "movies_df = movies_df.withColumn(\"ReleaseYear\", regexp_extract(\"Title\", year_pattern, 1).cast(IntegerType())) \\\n",
    "                     .withColumn(\"Title\", trim(col(\"Title\")))\n",
    "\n",
    "# As per the condition mentioned in the requirement we are just taking movies which are released after \"1989\"\n",
    "final_movies_df = movies_df.filter(col(\"ReleaseYear\") > 1989)\n",
    "\n",
    "# movies_df.printSchema()\n",
    "# movies_df.show(5,truncate=False)\n",
    "movies_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d2c28-4217-4924-9528-88c483e4b8a6",
   "metadata": {},
   "source": [
    "#### == Reading \"users.dat\" in pyspark dataframe \"users_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3243bbf-f297-48c4-9ae9-e5c459fd6409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom schema for users_df\n",
    "users_schema = StructType([\n",
    "    StructField(\"UserID\", IntegerType(), True),\n",
    "    StructField(\"Gender\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Occupation\", IntegerType(), True),\n",
    "    StructField(\"Zip-code\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create users_df dataframe by reading data from file users.dat\n",
    "users_df = spark.read.format('csv') \\\n",
    "                    .option(\"sep\", \"::\") \\\n",
    "                    .schema(users_schema) \\\n",
    "                    .option(\"mode\", \"permissive\") \\\n",
    "                    .load(r\"..\\..\\staging\\dimension\\users.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69d6ec30-6a62-46e8-9af6-2f4bdac31a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4942"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As per the condition mentioned in the requirement we are taking users who falls under the Age range of (18 - 49)\n",
    "users_df = users_df.filter((col(\"Age\") >= 18) & (col(\"Age\") <= 49 ) )\n",
    "\n",
    "# As \"Zip-code\" column is not required in our further transformation but but we are filling the \"nulls\" with constant '1'\n",
    "users_df = users_df.fillna({\"Zip-code\": 1}) \n",
    "\n",
    "# users_df.printSchema()\n",
    "# users_df.show(5)\n",
    "users_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8255613-43b7-40b8-86d8-ba9efed205e7",
   "metadata": {},
   "source": [
    "#### == Reading \"ratings.dat\" in pyspark dataframe \"ratings_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ad4c13-8fb1-4835-ae1e-16cc99f8d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom schema for ratings_df\n",
    "ratings_schema = StructType([\n",
    "    StructField(\"UserID\", IntegerType(), True),\n",
    "    StructField(\"MovieID\", IntegerType(), True),\n",
    "    StructField(\"Rating\", IntegerType(), True),\n",
    "    StructField(\"Timestamp\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create ratings_df dataframe by reading data from file ratings.dat\n",
    "ratings_df = spark.read.format('csv') \\\n",
    "                    .option(\"sep\", \"::\") \\\n",
    "                    .schema(ratings_schema) \\\n",
    "                    .option(\"mode\", \"permissive\") \\\n",
    "                    .load(r\"..\\..\\staging\\fact\\ratings.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "398b9c43-a6eb-41a7-91fa-4e95a67102cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets change the dataType of Rating column from IntegerType to FloatType\n",
    "ratings_df = ratings_df.withColumn(\"Rating\", ratings_df.Rating.cast(FloatType()))\n",
    "\n",
    "# ratings_df.printSchema()\n",
    "# ratings_df.show(5)\n",
    "ratings_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3153f4d-e4a1-44d3-b611-071a21a4a954",
   "metadata": {},
   "source": [
    "#### == Join all three \"movie_df, users_df, ratings_df\" DataFrames  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a6b6517-ff56-4daa-b54f-c536b70d19d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1814382"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform join operation, as movie_df and users_df are the small dataframes so we are using bradcast join\n",
    "join_df = ratings_df.join(broadcast(movies_df), \"MovieID\").join(broadcast(users_df), \"UserID\")\n",
    "\n",
    "# Genres column have multiple genres for one single movie and which is \"|\" separated so we need to explode it\n",
    "join_df = join_df.withColumn(\"Genres\", explode(split(col(\"Genres\"), \"\\\\|\")))\n",
    "\n",
    "# join_df.printSchema()\n",
    "# join_df.show()\n",
    "join_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce91e23-4f1f-4a78-a572-1c6ab793dd00",
   "metadata": {},
   "source": [
    "#### == Calculating the average ratings, per genre and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "679f7942-59b6-427f-bda9-f5955f7ec099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Genres: string (nullable = false)\n",
      " |-- ReleaseYear: integer (nullable = true)\n",
      " |-- AverageRating: double (nullable = true)\n",
      " |-- RatingCountPerGenre: long (nullable = false)\n",
      "\n",
      "+-----------+-----------+------------------+-------------------+\n",
      "|     Genres|ReleaseYear|     AverageRating|RatingCountPerGenre|\n",
      "+-----------+-----------+------------------+-------------------+\n",
      "|     Action|       2000|3.4562582844158305|              10562|\n",
      "|        War|       2000| 3.720183486238532|               1090|\n",
      "|Documentary|       2000|              3.56|                375|\n",
      "|    Fantasy|       2000|2.4508196721311477|                122|\n",
      "|     Comedy|       2000| 3.393928035982009|              13340|\n",
      "|     Horror|       2000|2.8681214421252372|               2108|\n",
      "|  Adventure|       2000|  3.02740408570005|               2007|\n",
      "| Children's|       2000| 3.279113625648279|               2121|\n",
      "|    Musical|       2000|3.8636363636363638|                176|\n",
      "|      Drama|       2000| 3.607611211108254|              11667|\n",
      "|   Thriller|       2000| 3.208319049251514|               8751|\n",
      "|  Animation|       2000|3.3786209710322317|               2451|\n",
      "|     Sci-Fi|       2000| 3.138364779874214|               4929|\n",
      "|      Crime|       2000|  3.15521327014218|               1688|\n",
      "|    Romance|       2000|3.2027822364901017|               1869|\n",
      "|    Mystery|       2000|2.7005758157389637|                521|\n",
      "|      Drama|       1999|3.6150596225223093|              25326|\n",
      "|    Fantasy|       1999|3.3858742463393625|               2322|\n",
      "|  Adventure|       1999|3.3409865470852016|               5575|\n",
      "|     Comedy|       1999|3.5045447494958895|              32235|\n",
      "+-----------+-----------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "895"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the average rating, per Genre and Year\n",
    "rating_report = join_df.groupBy(\"Genres\", \"ReleaseYear\") \\\n",
    "                  .agg(avg(\"Rating\").alias(\"AverageRating\"), count(\"Genres\").alias(\"RatingCountPerGenre\")) \\\n",
    "                  .orderBy(col(\"ReleaseYear\").desc())\n",
    "\n",
    "rating_report.printSchema()\n",
    "rating_report.show()\n",
    "rating_report.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524dee2d-80c6-4aa3-a864-d35ab4aef98e",
   "metadata": {},
   "source": [
    "#### == Writing rating_report dataframe to output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5354b18-8814-4728-b911-fd2632efe5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "._SUCCESS.crc\n",
      "Genres=Action\n",
      "Genres=Adventure\n",
      "Genres=Animation\n",
      "Genres=Children%27s\n",
      "Genres=Comedy\n",
      "Genres=Crime\n",
      "Genres=Documentary\n",
      "Genres=Drama\n",
      "Genres=Fantasy\n",
      "Genres=Film-Noir\n",
      "Genres=Horror\n",
      "Genres=Musical\n",
      "Genres=Mystery\n",
      "Genres=Romance\n",
      "Genres=Sci-Fi\n",
      "Genres=Thriller\n",
      "Genres=War\n",
      "Genres=Western\n",
      "_SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# Writing rating_report dataframe to output folder. Here we have partitioned the output data with reference to \"Genres\" column\n",
    "filePath = r\"..\\..\\output\\Jupyter_report\"\n",
    "format = \"orc\"\n",
    "mode = \"overwrite\"\n",
    "rating_report.write \\\n",
    "        .format(format) \\\n",
    "        .mode(mode) \\\n",
    "        .partitionBy(\"Genres\") \\\n",
    "        .save(filePath)\n",
    "\n",
    "# Validating the ouput files\n",
    "import os\n",
    "for file in os.listdir(filePath):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4195773b-e348-4599-b4a6-b933c6b6ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b8144d5-0405-49cc-ae7b-4164ee65cef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of 'Movielens_data_pipeline' script is \n",
      " --- :103.99248504638672 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"Execution time of 'Movielens_data_pipeline' script is \\n --- :%s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
